{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import expression status of WBP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "wbp2 = pd.read_csv('wbp2stat.csv')\n",
    "wbp2= wbp2.values.tolist()\n",
    "print(len(wbp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000 = pd.read_csv('top1000exp.csv')\n",
    "top1000 = top1000.transpose()\n",
    "top1000 = top1000.values.tolist()\n",
    "bot1000 = pd.read_csv('bot1000exp.csv')\n",
    "bot1000 = bot1000.transpose()\n",
    "bot1000 = bot1000.values.tolist()\n",
    "rand1000 = pd.read_csv('rand1000exp.csv')\n",
    "rand1000 = rand1000.transpose()\n",
    "rand1000 = rand1000.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct for class imablance with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array(wbp2)\n",
    "class_diff = np.count_nonzero(x == 0) - np.count_nonzero(x == 1)\n",
    "\n",
    "#Extracting WBP2 upregulation samples\n",
    "idx = np.where(x == 1)[0].tolist()\n",
    "for j in range(0,3):\n",
    "    if j == 0:\n",
    "        TN = top1000\n",
    "    elif j == 1:\n",
    "        TN = bot1000\n",
    "    else:\n",
    "        TN = rand1000\n",
    "    wbp2upTN = []\n",
    "    for i in idx:\n",
    "        wbp2upTN.append(TN[i])\n",
    "    idx = np.random.permutation(len(wbp2upTN))\n",
    "    wbp2upTN = [wbp2upTN[i] for i in idx]\n",
    "    wbp2upTN = wbp2upTN [0:class_diff]\n",
    "    #Adding noise to create synthetic samples\n",
    "    noise = np.random.normal(1,0.1,len(wbp2upTN[0]))\n",
    "    noiseTN = wbp2upTN * noise\n",
    "    #Adding the synthetic sample to the dataset\n",
    "    TN = list(itertools.chain(TN, noiseTN))\n",
    "    if j == 0:\n",
    "        top1000 = TN\n",
    "    elif j == 1:\n",
    "        bot1000 = TN\n",
    "    else:\n",
    "        rand1000 = TN\n",
    "\n",
    "for i in range(1,class_diff):\n",
    "    wbp2.append([1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing sample size with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n",
      "596\n",
      "1192\n",
      "2384\n",
      "4768\n",
      "9536\n",
      "19072\n",
      "38144\n",
      "76288\n",
      "152576\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,10):\n",
    "    wbp2 = wbp2 + wbp2\n",
    "    #Generate synthetic data for top1000\n",
    "    noise = np.random.normal(1,0.1,len(top1000[0]))\n",
    "    noiseTN = top1000 * noise\n",
    "    top1000 = list(itertools.chain(top1000, noiseTN))\n",
    "    #enerate synthetic data for bot1000\n",
    "    noise = np.random.normal(1,0.1,len(bot1000[0]))\n",
    "    noiseTN = bot1000 * noise\n",
    "    bot1000 = list(itertools.chain(bot1000, noiseTN))\n",
    "    #enerate synthetic data for rand1000\n",
    "    noise = np.random.normal(1,0.1,len(rand1000[0]))\n",
    "    noiseTN = rand1000 * noise\n",
    "    rand1000 = list(itertools.chain(rand1000, noiseTN))\n",
    "    print(len(wbp2))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000acc = []\n",
    "bot1000acc = []\n",
    "rand1000acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 22us/step - loss: 1.5883 - acc: 0.5288 - val_loss: 0.5598 - val_acc: 0.6420\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7867 - acc: 0.5826 - val_loss: 0.5355 - val_acc: 0.7185\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6938 - acc: 0.6186 - val_loss: 0.5134 - val_acc: 0.7608\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6412 - acc: 0.6362 - val_loss: 0.4983 - val_acc: 0.7969\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6107 - acc: 0.6531 - val_loss: 0.4946 - val_acc: 0.8040\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5874 - acc: 0.6754 - val_loss: 0.4765 - val_acc: 0.8338\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5673 - acc: 0.6884 - val_loss: 0.4602 - val_acc: 0.8496\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5404 - acc: 0.7076 - val_loss: 0.4471 - val_acc: 0.8695\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5215 - acc: 0.7213 - val_loss: 0.4274 - val_acc: 0.8781\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4998 - acc: 0.7369 - val_loss: 0.4056 - val_acc: 0.8876\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4839 - acc: 0.7553 - val_loss: 0.3954 - val_acc: 0.9044\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4665 - acc: 0.7658 - val_loss: 0.3863 - val_acc: 0.9099\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4541 - acc: 0.7780 - val_loss: 0.3573 - val_acc: 0.9306\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4382 - acc: 0.7904 - val_loss: 0.3466 - val_acc: 0.9379\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4264 - acc: 0.8001 - val_loss: 0.3356 - val_acc: 0.9349\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 20us/step - loss: 1.9368 - acc: 0.5181 - val_loss: 1.0853 - val_acc: 0.6072\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 1.1571 - acc: 0.5487 - val_loss: 0.8271 - val_acc: 0.6517\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 1.0000 - acc: 0.5675 - val_loss: 0.7220 - val_acc: 0.6640\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.8021 - acc: 0.5842 - val_loss: 0.6885 - val_acc: 0.6820\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7387 - acc: 0.5980 - val_loss: 0.6794 - val_acc: 0.6888\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7273 - acc: 0.6108 - val_loss: 0.6734 - val_acc: 0.7032\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7189 - acc: 0.6197 - val_loss: 0.6694 - val_acc: 0.7062\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7124 - acc: 0.6278 - val_loss: 0.6633 - val_acc: 0.7100\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7057 - acc: 0.6347 - val_loss: 0.6579 - val_acc: 0.7117\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6943 - acc: 0.6421 - val_loss: 0.6552 - val_acc: 0.7192\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6915 - acc: 0.6461 - val_loss: 0.6479 - val_acc: 0.7249\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6866 - acc: 0.6528 - val_loss: 0.6444 - val_acc: 0.7328\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6729 - acc: 0.6599 - val_loss: 0.6398 - val_acc: 0.7363\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6716 - acc: 0.6624 - val_loss: 0.6342 - val_acc: 0.7379\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6606 - acc: 0.6690 - val_loss: 0.6303 - val_acc: 0.7405\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 23us/step - loss: 1.4677 - acc: 0.5319 - val_loss: 0.7926 - val_acc: 0.5601\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.9294 - acc: 0.5449 - val_loss: 0.7659 - val_acc: 0.5964\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.8259 - acc: 0.5597 - val_loss: 0.7599 - val_acc: 0.5993\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7854 - acc: 0.5697 - val_loss: 0.7501 - val_acc: 0.6051\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7539 - acc: 0.5808 - val_loss: 0.7334 - val_acc: 0.6286\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.7188 - acc: 0.5955 - val_loss: 0.6186 - val_acc: 0.6535\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6860 - acc: 0.6054 - val_loss: 0.6037 - val_acc: 0.6748\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6719 - acc: 0.6189 - val_loss: 0.5853 - val_acc: 0.6892\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6514 - acc: 0.6284 - val_loss: 0.5692 - val_acc: 0.7085\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6369 - acc: 0.6375 - val_loss: 0.5536 - val_acc: 0.7214\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6221 - acc: 0.6482 - val_loss: 0.5353 - val_acc: 0.7420\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6116 - acc: 0.6499 - val_loss: 0.5189 - val_acc: 0.7513\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6028 - acc: 0.6594 - val_loss: 0.5081 - val_acc: 0.7565\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5936 - acc: 0.6657 - val_loss: 0.4978 - val_acc: 0.7640\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5825 - acc: 0.6717 - val_loss: 0.4881 - val_acc: 0.7671\n",
      "Current Loop\n",
      "0\n",
      "Time taken for this loop\n",
      "84.14319491386414\n",
      "Time left\n",
      "757.2887542247772\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 21us/step - loss: 1.7908 - acc: 0.5401 - val_loss: 0.5881 - val_acc: 0.6454\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.8361 - acc: 0.6148 - val_loss: 0.5094 - val_acc: 0.7354\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6802 - acc: 0.6538 - val_loss: 0.4670 - val_acc: 0.7791\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6176 - acc: 0.6761 - val_loss: 0.4478 - val_acc: 0.8391\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5803 - acc: 0.6867 - val_loss: 0.4380 - val_acc: 0.8339\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5420 - acc: 0.7079 - val_loss: 0.3995 - val_acc: 0.8487\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5235 - acc: 0.7202 - val_loss: 0.3984 - val_acc: 0.8795\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4941 - acc: 0.7407 - val_loss: 0.3621 - val_acc: 0.9289\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4790 - acc: 0.7537 - val_loss: 0.3390 - val_acc: 0.9267\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4599 - acc: 0.7663 - val_loss: 0.3636 - val_acc: 0.9056\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4483 - acc: 0.7766 - val_loss: 0.3425 - val_acc: 0.9367\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4306 - acc: 0.7881 - val_loss: 0.3026 - val_acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4139 - acc: 0.7964 - val_loss: 0.2799 - val_acc: 0.9543\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4071 - acc: 0.8013 - val_loss: 0.2880 - val_acc: 0.9577\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.3920 - acc: 0.8096 - val_loss: 0.2523 - val_acc: 0.9576\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 20us/step - loss: 1.7107 - acc: 0.5449 - val_loss: 0.8280 - val_acc: 0.6889\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.0846 - acc: 0.5694 - val_loss: 0.7611 - val_acc: 0.7149\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.9187 - acc: 0.5852 - val_loss: 0.6994 - val_acc: 0.7285\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8242 - acc: 0.6015 - val_loss: 0.6522 - val_acc: 0.7397\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7381 - acc: 0.6171 - val_loss: 0.6429 - val_acc: 0.7433\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7133 - acc: 0.6291 - val_loss: 0.6328 - val_acc: 0.7575\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6944 - acc: 0.6412 - val_loss: 0.6292 - val_acc: 0.7544\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6770 - acc: 0.6494 - val_loss: 0.6198 - val_acc: 0.7637\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6675 - acc: 0.6575 - val_loss: 0.6101 - val_acc: 0.7681\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6623 - acc: 0.6640 - val_loss: 0.6030 - val_acc: 0.7676\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6564 - acc: 0.6697 - val_loss: 0.5982 - val_acc: 0.7685\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6487 - acc: 0.6764 - val_loss: 0.5908 - val_acc: 0.7794\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6407 - acc: 0.6813 - val_loss: 0.5811 - val_acc: 0.7907\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6325 - acc: 0.6893 - val_loss: 0.5778 - val_acc: 0.7909\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6286 - acc: 0.6947 - val_loss: 0.5663 - val_acc: 0.8049\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 22us/step - loss: 1.6106 - acc: 0.5285 - val_loss: 0.8690 - val_acc: 0.6070\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.0634 - acc: 0.5504 - val_loss: 0.7576 - val_acc: 0.6147\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.9140 - acc: 0.5644 - val_loss: 0.7224 - val_acc: 0.6416\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8353 - acc: 0.5792 - val_loss: 0.7048 - val_acc: 0.6617\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7804 - acc: 0.5881 - val_loss: 0.6879 - val_acc: 0.6837\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7408 - acc: 0.6003 - val_loss: 0.6769 - val_acc: 0.6983\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7260 - acc: 0.6108 - val_loss: 0.6692 - val_acc: 0.7100\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7113 - acc: 0.6180 - val_loss: 0.6599 - val_acc: 0.7167\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7048 - acc: 0.6276 - val_loss: 0.6517 - val_acc: 0.7278\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6888 - acc: 0.6368 - val_loss: 0.6423 - val_acc: 0.7370\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6766 - acc: 0.6484 - val_loss: 0.6322 - val_acc: 0.7490\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6686 - acc: 0.6533 - val_loss: 0.6232 - val_acc: 0.7587\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6644 - acc: 0.6602 - val_loss: 0.6142 - val_acc: 0.7635\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6545 - acc: 0.6680 - val_loss: 0.6080 - val_acc: 0.7705\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6437 - acc: 0.6742 - val_loss: 0.5979 - val_acc: 0.7747\n",
      "Current Loop\n",
      "1\n",
      "Time taken for this loop\n",
      "83.14975786209106\n",
      "Time left\n",
      "665.1980628967285\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 20us/step - loss: 1.4500 - acc: 0.5499 - val_loss: 0.5580 - val_acc: 0.7081\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7886 - acc: 0.5911 - val_loss: 0.5191 - val_acc: 0.7176\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6506 - acc: 0.6236 - val_loss: 0.4992 - val_acc: 0.7790\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6042 - acc: 0.6449 - val_loss: 0.4828 - val_acc: 0.8148\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5743 - acc: 0.6626 - val_loss: 0.4707 - val_acc: 0.8276\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5563 - acc: 0.6777 - val_loss: 0.4587 - val_acc: 0.8372\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5379 - acc: 0.6910 - val_loss: 0.4451 - val_acc: 0.8501\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5256 - acc: 0.7050 - val_loss: 0.4344 - val_acc: 0.8507\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5100 - acc: 0.7186 - val_loss: 0.4168 - val_acc: 0.8740\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4993 - acc: 0.7277 - val_loss: 0.4068 - val_acc: 0.8803\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4845 - acc: 0.7401 - val_loss: 0.3918 - val_acc: 0.9010\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4728 - acc: 0.7504 - val_loss: 0.3758 - val_acc: 0.9028\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4608 - acc: 0.7630 - val_loss: 0.3618 - val_acc: 0.9083\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4475 - acc: 0.7750 - val_loss: 0.3491 - val_acc: 0.9218\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4338 - acc: 0.7837 - val_loss: 0.3327 - val_acc: 0.9186\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 20us/step - loss: 1.8721 - acc: 0.5182 - val_loss: 0.9383 - val_acc: 0.6063\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.1540 - acc: 0.5512 - val_loss: 0.7857 - val_acc: 0.6643\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.9952 - acc: 0.5707 - val_loss: 0.7729 - val_acc: 0.6707\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8842 - acc: 0.5793 - val_loss: 0.7053 - val_acc: 0.6804\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8135 - acc: 0.5842 - val_loss: 0.6572 - val_acc: 0.7040\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7469 - acc: 0.5922 - val_loss: 0.6508 - val_acc: 0.6994\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7003 - acc: 0.6014 - val_loss: 0.6438 - val_acc: 0.7062\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6663 - acc: 0.6100 - val_loss: 0.6361 - val_acc: 0.7192\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6245 - acc: 0.6136 - val_loss: 0.5377 - val_acc: 0.7258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5969 - acc: 0.6238 - val_loss: 0.5266 - val_acc: 0.7272\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5875 - acc: 0.6319 - val_loss: 0.5183 - val_acc: 0.7375\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5817 - acc: 0.6409 - val_loss: 0.5114 - val_acc: 0.7517\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5720 - acc: 0.6509 - val_loss: 0.5056 - val_acc: 0.7667\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5661 - acc: 0.6579 - val_loss: 0.4984 - val_acc: 0.7732\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5591 - acc: 0.6639 - val_loss: 0.4918 - val_acc: 0.7682\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 22us/step - loss: 1.7209 - acc: 0.5175 - val_loss: 0.9194 - val_acc: 0.5679\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.1141 - acc: 0.5399 - val_loss: 0.8341 - val_acc: 0.5647\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.9584 - acc: 0.5564 - val_loss: 0.8184 - val_acc: 0.6003\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8804 - acc: 0.5769 - val_loss: 0.8042 - val_acc: 0.6320\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.8374 - acc: 0.5914 - val_loss: 0.6414 - val_acc: 0.6586\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7711 - acc: 0.6036 - val_loss: 0.6829 - val_acc: 0.6917\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7274 - acc: 0.6134 - val_loss: 0.6691 - val_acc: 0.7164\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7137 - acc: 0.6223 - val_loss: 0.6557 - val_acc: 0.7348\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7020 - acc: 0.6322 - val_loss: 0.6404 - val_acc: 0.7476\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6917 - acc: 0.6399 - val_loss: 0.6304 - val_acc: 0.7554\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6825 - acc: 0.6460 - val_loss: 0.6095 - val_acc: 0.7675\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6761 - acc: 0.6522 - val_loss: 0.6076 - val_acc: 0.7736\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6673 - acc: 0.6613 - val_loss: 0.5761 - val_acc: 0.7854\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6526 - acc: 0.6678 - val_loss: 0.5047 - val_acc: 0.7957\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6489 - acc: 0.6727 - val_loss: 0.5612 - val_acc: 0.8025\n",
      "Current Loop\n",
      "2\n",
      "Time taken for this loop\n",
      "81.48951268196106\n",
      "Time left\n",
      "570.4265887737274\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 22us/step - loss: 1.6692 - acc: 0.5502 - val_loss: 0.5320 - val_acc: 0.7464\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7408 - acc: 0.6134 - val_loss: 0.4752 - val_acc: 0.7984\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6348 - acc: 0.6411 - val_loss: 0.4596 - val_acc: 0.8360\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5918 - acc: 0.6654 - val_loss: 0.4407 - val_acc: 0.8394\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5652 - acc: 0.6823 - val_loss: 0.4243 - val_acc: 0.8550\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5435 - acc: 0.7006 - val_loss: 0.4104 - val_acc: 0.8633\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5241 - acc: 0.7187 - val_loss: 0.3974 - val_acc: 0.8795\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5082 - acc: 0.7292 - val_loss: 0.3826 - val_acc: 0.8862\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4915 - acc: 0.7405 - val_loss: 0.3695 - val_acc: 0.8955\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4772 - acc: 0.7531 - val_loss: 0.3562 - val_acc: 0.8972\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4639 - acc: 0.7639 - val_loss: 0.3433 - val_acc: 0.9051\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4492 - acc: 0.7732 - val_loss: 0.3290 - val_acc: 0.9129\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4331 - acc: 0.7831 - val_loss: 0.3193 - val_acc: 0.9355\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4228 - acc: 0.7903 - val_loss: 0.3037 - val_acc: 0.9366\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4067 - acc: 0.7999 - val_loss: 0.2889 - val_acc: 0.9338\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 21us/step - loss: 2.3791 - acc: 0.5318 - val_loss: 1.1457 - val_acc: 0.5915\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.3007 - acc: 0.5665 - val_loss: 0.9632 - val_acc: 0.6270\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.1103 - acc: 0.5938 - val_loss: 0.9027 - val_acc: 0.6577\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.0092 - acc: 0.6114 - val_loss: 0.8391 - val_acc: 0.6764\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.9354 - acc: 0.6203 - val_loss: 0.7658 - val_acc: 0.6776\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8495 - acc: 0.6285 - val_loss: 0.7080 - val_acc: 0.6878\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7721 - acc: 0.6299 - val_loss: 0.6588 - val_acc: 0.6978\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7207 - acc: 0.6395 - val_loss: 0.6466 - val_acc: 0.7042\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7014 - acc: 0.6472 - val_loss: 0.6390 - val_acc: 0.7112\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6883 - acc: 0.6541 - val_loss: 0.6291 - val_acc: 0.7203\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6782 - acc: 0.6633 - val_loss: 0.6231 - val_acc: 0.7301\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6707 - acc: 0.6688 - val_loss: 0.6116 - val_acc: 0.7414\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6662 - acc: 0.6744 - val_loss: 0.6004 - val_acc: 0.7496\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6544 - acc: 0.6808 - val_loss: 0.5934 - val_acc: 0.7646\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6496 - acc: 0.6859 - val_loss: 0.5876 - val_acc: 0.7739\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 23us/step - loss: 1.5230 - acc: 0.5326 - val_loss: 0.8233 - val_acc: 0.6061 2s - loss: 2.017\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.9872 - acc: 0.5603 - val_loss: 0.7399 - val_acc: 0.6420\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8840 - acc: 0.5716 - val_loss: 0.7290 - val_acc: 0.6439\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8074 - acc: 0.5857 - val_loss: 0.7103 - val_acc: 0.6671\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7595 - acc: 0.5973 - val_loss: 0.7001 - val_acc: 0.6894\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 19us/step - loss: 0.7390 - acc: 0.6141 - val_loss: 0.6928 - val_acc: 0.7115\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 19us/step - loss: 0.7234 - acc: 0.6253 - val_loss: 0.6826 - val_acc: 0.7227\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 19us/step - loss: 0.7156 - acc: 0.6331 - val_loss: 0.5882 - val_acc: 0.7355\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7019 - acc: 0.6450 - val_loss: 0.6634 - val_acc: 0.7471\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6947 - acc: 0.6516 - val_loss: 0.6533 - val_acc: 0.7555\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6869 - acc: 0.6604 - val_loss: 0.6445 - val_acc: 0.7629\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6814 - acc: 0.6647 - val_loss: 0.6366 - val_acc: 0.7663\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6711 - acc: 0.6719 - val_loss: 0.6270 - val_acc: 0.7776\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6643 - acc: 0.6797 - val_loss: 0.6184 - val_acc: 0.7791\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6561 - acc: 0.6870 - val_loss: 0.6102 - val_acc: 0.7883\n",
      "Current Loop\n",
      "3\n",
      "Time taken for this loop\n",
      "82.47560524940491\n",
      "Time left\n",
      "494.85363149642944\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 22us/step - loss: 1.4799 - acc: 0.5624 - val_loss: 0.5328 - val_acc: 0.7278\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7206 - acc: 0.6293 - val_loss: 0.4836 - val_acc: 0.7984\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6195 - acc: 0.6662 - val_loss: 0.4578 - val_acc: 0.8181\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5776 - acc: 0.6878 - val_loss: 0.4335 - val_acc: 0.8373\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5380 - acc: 0.7097 - val_loss: 0.4157 - val_acc: 0.8490\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5110 - acc: 0.7301 - val_loss: 0.3993 - val_acc: 0.8713\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4893 - acc: 0.7473 - val_loss: 0.3778 - val_acc: 0.8786\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4707 - acc: 0.7653 - val_loss: 0.3685 - val_acc: 0.9163\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4525 - acc: 0.7777 - val_loss: 0.3435 - val_acc: 0.8969\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4342 - acc: 0.7893 - val_loss: 0.3347 - val_acc: 0.9370\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4196 - acc: 0.7995 - val_loss: 0.3090 - val_acc: 0.9094\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4018 - acc: 0.8101 - val_loss: 0.2924 - val_acc: 0.9117\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.3901 - acc: 0.8185 - val_loss: 0.2765 - val_acc: 0.9212\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.3731 - acc: 0.8277 - val_loss: 0.2637 - val_acc: 0.9362\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.3612 - acc: 0.8336 - val_loss: 0.2722 - val_acc: 0.9514\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 22us/step - loss: 1.7626 - acc: 0.5138 - val_loss: 0.8591 - val_acc: 0.5368\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 1.0924 - acc: 0.5268 - val_loss: 0.6469 - val_acc: 0.5559\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.9091 - acc: 0.5375 - val_loss: 0.6307 - val_acc: 0.5900\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8272 - acc: 0.5521 - val_loss: 0.6170 - val_acc: 0.6254\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7777 - acc: 0.5658 - val_loss: 0.6086 - val_acc: 0.6136\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7319 - acc: 0.5804 - val_loss: 0.6017 - val_acc: 0.6431\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6908 - acc: 0.5886 - val_loss: 0.5925 - val_acc: 0.6743\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6523 - acc: 0.6002 - val_loss: 0.5886 - val_acc: 0.6804\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6398 - acc: 0.6092 - val_loss: 0.5809 - val_acc: 0.7009\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6300 - acc: 0.6195 - val_loss: 0.5730 - val_acc: 0.7153\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6222 - acc: 0.6236 - val_loss: 0.5654 - val_acc: 0.7243\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6161 - acc: 0.6320 - val_loss: 0.5602 - val_acc: 0.7264\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6104 - acc: 0.6365 - val_loss: 0.5519 - val_acc: 0.7362\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6023 - acc: 0.6426 - val_loss: 0.5450 - val_acc: 0.7454\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5960 - acc: 0.6504 - val_loss: 0.5360 - val_acc: 0.7551\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 24us/step - loss: 2.0633 - acc: 0.5335 - val_loss: 0.8995 - val_acc: 0.5879\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.1573 - acc: 0.5640 - val_loss: 0.7936 - val_acc: 0.6527\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.9469 - acc: 0.5821 - val_loss: 0.7633 - val_acc: 0.6918\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8454 - acc: 0.6019 - val_loss: 0.6899 - val_acc: 0.7101\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7787 - acc: 0.6221 - val_loss: 0.6272 - val_acc: 0.7302\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7318 - acc: 0.6399 - val_loss: 0.6199 - val_acc: 0.7452\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6823 - acc: 0.6539 - val_loss: 0.5921 - val_acc: 0.7608\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6586 - acc: 0.6623 - val_loss: 0.5720 - val_acc: 0.7625\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6392 - acc: 0.6752 - val_loss: 0.5342 - val_acc: 0.7623\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6281 - acc: 0.6822 - val_loss: 0.5544 - val_acc: 0.7671\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6169 - acc: 0.6897 - val_loss: 0.5496 - val_acc: 0.7720\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6053 - acc: 0.6983 - val_loss: 0.4594 - val_acc: 0.7800\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6003 - acc: 0.7062 - val_loss: 0.4871 - val_acc: 0.7859\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5904 - acc: 0.7108 - val_loss: 0.4436 - val_acc: 0.7906\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5802 - acc: 0.7192 - val_loss: 0.5253 - val_acc: 0.7977\n",
      "Current Loop\n",
      "4\n",
      "Time taken for this loop\n",
      "83.06939697265625\n",
      "Time left\n",
      "415.34698486328125\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 23us/step - loss: 1.3844 - acc: 0.5595 - val_loss: 0.5693 - val_acc: 0.6641\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.8075 - acc: 0.5892 - val_loss: 0.5611 - val_acc: 0.7042\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6803 - acc: 0.6331 - val_loss: 0.5238 - val_acc: 0.8028\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6169 - acc: 0.6719 - val_loss: 0.4947 - val_acc: 0.8258\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5820 - acc: 0.6912 - val_loss: 0.4695 - val_acc: 0.8493\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5536 - acc: 0.7107 - val_loss: 0.4484 - val_acc: 0.8676\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5308 - acc: 0.7225 - val_loss: 0.4315 - val_acc: 0.8772\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5085 - acc: 0.7396 - val_loss: 0.4099 - val_acc: 0.8663\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4936 - acc: 0.7547 - val_loss: 0.3959 - val_acc: 0.8907\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4728 - acc: 0.7668 - val_loss: 0.3757 - val_acc: 0.8981\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4570 - acc: 0.7766 - val_loss: 0.3631 - val_acc: 0.9144\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4405 - acc: 0.7911 - val_loss: 0.3421 - val_acc: 0.9268\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4278 - acc: 0.7996 - val_loss: 0.3146 - val_acc: 0.9231\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.4175 - acc: 0.8052 - val_loss: 0.3075 - val_acc: 0.9061\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4035 - acc: 0.8122 - val_loss: 0.2943 - val_acc: 0.9201\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 23us/step - loss: 1.7671 - acc: 0.5201 - val_loss: 0.9058 - val_acc: 0.5840\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.1127 - acc: 0.5434 - val_loss: 0.7921 - val_acc: 0.6259\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.9336 - acc: 0.5633 - val_loss: 0.7353 - val_acc: 0.6393\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8410 - acc: 0.5721 - val_loss: 0.7195 - val_acc: 0.6422\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7851 - acc: 0.5807 - val_loss: 0.7104 - val_acc: 0.6619\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7571 - acc: 0.5873 - val_loss: 0.7034 - val_acc: 0.6606\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6885 - acc: 0.5960 - val_loss: 0.6019 - val_acc: 0.6811\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6521 - acc: 0.5994 - val_loss: 0.5968 - val_acc: 0.6964\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6414 - acc: 0.6065 - val_loss: 0.5896 - val_acc: 0.7036\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6326 - acc: 0.6133 - val_loss: 0.5837 - val_acc: 0.7132\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6266 - acc: 0.6194 - val_loss: 0.5754 - val_acc: 0.7199\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6185 - acc: 0.6235 - val_loss: 0.5707 - val_acc: 0.7278\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6126 - acc: 0.6321 - val_loss: 0.5641 - val_acc: 0.7316\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6039 - acc: 0.6339 - val_loss: 0.5593 - val_acc: 0.7323\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6011 - acc: 0.6411 - val_loss: 0.5526 - val_acc: 0.7391\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 24us/step - loss: 1.4101 - acc: 0.5344 - val_loss: 0.6845 - val_acc: 0.6274\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.0209 - acc: 0.5553 - val_loss: 0.7232 - val_acc: 0.6464\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8896 - acc: 0.5673 - val_loss: 0.7096 - val_acc: 0.6732\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.8109 - acc: 0.5837 - val_loss: 0.6530 - val_acc: 0.6903\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7611 - acc: 0.5980 - val_loss: 0.6031 - val_acc: 0.7089\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7244 - acc: 0.6112 - val_loss: 0.6430 - val_acc: 0.7204\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7095 - acc: 0.6186 - val_loss: 0.5983 - val_acc: 0.7313\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6899 - acc: 0.6335 - val_loss: 0.5371 - val_acc: 0.7475\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6777 - acc: 0.6398 - val_loss: 0.5376 - val_acc: 0.7573\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6639 - acc: 0.6503 - val_loss: 0.5367 - val_acc: 0.7675\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6472 - acc: 0.6573 - val_loss: 0.5224 - val_acc: 0.7722\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6366 - acc: 0.6654 - val_loss: 0.5000 - val_acc: 0.7762\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6171 - acc: 0.6729 - val_loss: 0.4917 - val_acc: 0.7758\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5999 - acc: 0.6766 - val_loss: 0.4824 - val_acc: 0.7774\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5689 - acc: 0.6867 - val_loss: 0.4724 - val_acc: 0.7839\n",
      "Current Loop\n",
      "5\n",
      "Time taken for this loop\n",
      "82.89027404785156\n",
      "Time left\n",
      "331.56109619140625\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 24us/step - loss: 1.4317 - acc: 0.5329 - val_loss: 0.6353 - val_acc: 0.6080\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7867 - acc: 0.5684 - val_loss: 0.6104 - val_acc: 0.6373\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6861 - acc: 0.5814 - val_loss: 0.5886 - val_acc: 0.6772\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6370 - acc: 0.6090 - val_loss: 0.5695 - val_acc: 0.7162\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6075 - acc: 0.6357 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5868 - acc: 0.6595 - val_loss: 0.5218 - val_acc: 0.7776\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5659 - acc: 0.6765 - val_loss: 0.4996 - val_acc: 0.7995\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5506 - acc: 0.6930 - val_loss: 0.4785 - val_acc: 0.8180\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5342 - acc: 0.7059 - val_loss: 0.4607 - val_acc: 0.8342\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5221 - acc: 0.7173 - val_loss: 0.4459 - val_acc: 0.8643\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5062 - acc: 0.7274 - val_loss: 0.4274 - val_acc: 0.8827\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4887 - acc: 0.7416 - val_loss: 0.4058 - val_acc: 0.8925\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4761 - acc: 0.7518 - val_loss: 0.4014 - val_acc: 0.8919\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4625 - acc: 0.7615 - val_loss: 0.3690 - val_acc: 0.9210\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4464 - acc: 0.7710 - val_loss: 0.3489 - val_acc: 0.9305\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 2s 23us/step - loss: 2.0361 - acc: 0.5334 - val_loss: 1.0734 - val_acc: 0.6202\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.1850 - acc: 0.5673 - val_loss: 1.0125 - val_acc: 0.6291\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 1.0049 - acc: 0.5813 - val_loss: 0.8464 - val_acc: 0.6325\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.9039 - acc: 0.5883 - val_loss: 0.6879 - val_acc: 0.6489\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8316 - acc: 0.5996 - val_loss: 0.6741 - val_acc: 0.6719\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7616 - acc: 0.6109 - val_loss: 0.5831 - val_acc: 0.7014\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7275 - acc: 0.6166 - val_loss: 0.5638 - val_acc: 0.7123\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6717 - acc: 0.6227 - val_loss: 0.5516 - val_acc: 0.7249\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6100 - acc: 0.6322 - val_loss: 0.5403 - val_acc: 0.7390\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5999 - acc: 0.6430 - val_loss: 0.5274 - val_acc: 0.7584\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5918 - acc: 0.6469 - val_loss: 0.5187 - val_acc: 0.7672\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5827 - acc: 0.6583 - val_loss: 0.5105 - val_acc: 0.7739\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5757 - acc: 0.6610 - val_loss: 0.5010 - val_acc: 0.7757\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.5694 - acc: 0.6652 - val_loss: 0.4944 - val_acc: 0.7794\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5622 - acc: 0.6715 - val_loss: 0.4879 - val_acc: 0.7795\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 25us/step - loss: 1.6694 - acc: 0.5222 - val_loss: 0.8340 - val_acc: 0.6474\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.0695 - acc: 0.5513 - val_loss: 0.7279 - val_acc: 0.6808\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.9017 - acc: 0.5681 - val_loss: 0.6980 - val_acc: 0.6939\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8205 - acc: 0.5818 - val_loss: 0.6906 - val_acc: 0.7143\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7777 - acc: 0.5904 - val_loss: 0.6856 - val_acc: 0.7220\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7528 - acc: 0.5980 - val_loss: 0.6817 - val_acc: 0.7268\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7336 - acc: 0.6131 - val_loss: 0.6761 - val_acc: 0.7294\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7228 - acc: 0.6255 - val_loss: 0.6687 - val_acc: 0.7318\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7117 - acc: 0.6342 - val_loss: 0.6584 - val_acc: 0.7457\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6981 - acc: 0.6474 - val_loss: 0.6014 - val_acc: 0.7527\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6857 - acc: 0.6593 - val_loss: 0.6353 - val_acc: 0.7535\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6723 - acc: 0.6646 - val_loss: 0.5484 - val_acc: 0.7589\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6680 - acc: 0.6749 - val_loss: 0.5590 - val_acc: 0.7631\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6437 - acc: 0.6826 - val_loss: 0.5225 - val_acc: 0.7675\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6139 - acc: 0.6923 - val_loss: 0.5052 - val_acc: 0.7716\n",
      "Current Loop\n",
      "6\n",
      "Time taken for this loop\n",
      "83.27137112617493\n",
      "Time left\n",
      "249.81411337852478\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 24us/step - loss: 1.3023 - acc: 0.5057 - val_loss: 0.6677 - val_acc: 0.4943\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.8026 - acc: 0.5230 - val_loss: 0.6608 - val_acc: 0.5374\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7254 - acc: 0.5333 - val_loss: 0.6614 - val_acc: 0.5553\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6969 - acc: 0.5431 - val_loss: 0.6606 - val_acc: 0.5596\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6784 - acc: 0.5576 - val_loss: 0.6575 - val_acc: 0.5619\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6668 - acc: 0.5656 - val_loss: 0.6524 - val_acc: 0.5728\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6583 - acc: 0.5734 - val_loss: 0.6442 - val_acc: 0.5886\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6513 - acc: 0.5807 - val_loss: 0.6348 - val_acc: 0.6044\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6417 - acc: 0.5894 - val_loss: 0.6243 - val_acc: 0.6176\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6331 - acc: 0.5977 - val_loss: 0.6127 - val_acc: 0.6173\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6247 - acc: 0.6049 - val_loss: 0.6019 - val_acc: 0.6264\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6171 - acc: 0.6107 - val_loss: 0.5917 - val_acc: 0.6386\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6087 - acc: 0.6175 - val_loss: 0.5797 - val_acc: 0.6520\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5977 - acc: 0.6312 - val_loss: 0.5645 - val_acc: 0.6780\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5872 - acc: 0.6444 - val_loss: 0.5461 - val_acc: 0.6918\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 24us/step - loss: 1.5085 - acc: 0.5137 - val_loss: 0.8439 - val_acc: 0.5239\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 1.0580 - acc: 0.5258 - val_loss: 0.6947 - val_acc: 0.5482\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.9043 - acc: 0.5302 - val_loss: 0.7079 - val_acc: 0.5477\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8256 - acc: 0.5367 - val_loss: 0.6705 - val_acc: 0.5539\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7623 - acc: 0.5376 - val_loss: 0.6731 - val_acc: 0.5610\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7289 - acc: 0.5476 - val_loss: 0.6714 - val_acc: 0.5735\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7062 - acc: 0.5563 - val_loss: 0.6689 - val_acc: 0.6038\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6784 - acc: 0.5642 - val_loss: 0.6509 - val_acc: 0.6373\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6630 - acc: 0.5690 - val_loss: 0.6454 - val_acc: 0.6417\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6543 - acc: 0.5731 - val_loss: 0.6371 - val_acc: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6480 - acc: 0.5769 - val_loss: 0.6296 - val_acc: 0.6681\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6429 - acc: 0.5850 - val_loss: 0.6219 - val_acc: 0.6763\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6388 - acc: 0.5875 - val_loss: 0.6157 - val_acc: 0.6770\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6344 - acc: 0.5931 - val_loss: 0.6090 - val_acc: 0.6824\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6278 - acc: 0.6028 - val_loss: 0.6018 - val_acc: 0.6964\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 26us/step - loss: 1.4701 - acc: 0.5213 - val_loss: 0.8032 - val_acc: 0.5706\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.0305 - acc: 0.5383 - val_loss: 0.7507 - val_acc: 0.5965\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.9322 - acc: 0.5472 - val_loss: 0.7364 - val_acc: 0.6134\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8661 - acc: 0.5589 - val_loss: 0.6378 - val_acc: 0.6128\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8236 - acc: 0.5707 - val_loss: 0.7039 - val_acc: 0.6198\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7786 - acc: 0.5804 - val_loss: 0.6276 - val_acc: 0.6279\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7559 - acc: 0.5888 - val_loss: 0.6235 - val_acc: 0.6350\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7337 - acc: 0.5933 - val_loss: 0.5972 - val_acc: 0.6408\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.7125 - acc: 0.6025 - val_loss: 0.5884 - val_acc: 0.6503\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6904 - acc: 0.6102 - val_loss: 0.5812 - val_acc: 0.6689\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6718 - acc: 0.6193 - val_loss: 0.5717 - val_acc: 0.6957\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6602 - acc: 0.6336 - val_loss: 0.5589 - val_acc: 0.7201\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6427 - acc: 0.6398 - val_loss: 0.5460 - val_acc: 0.7412\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6149 - acc: 0.6491 - val_loss: 0.5353 - val_acc: 0.7487\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.5788 - acc: 0.6619 - val_loss: 0.5231 - val_acc: 0.7605\n",
      "Current Loop\n",
      "7\n",
      "Time taken for this loop\n",
      "84.16897487640381\n",
      "Time left\n",
      "168.33794975280762\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 26us/step - loss: 1.3792 - acc: 0.5233 - val_loss: 0.7996 - val_acc: 0.6390\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.8496 - acc: 0.5607 - val_loss: 0.5552 - val_acc: 0.7413\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6791 - acc: 0.5924 - val_loss: 0.5271 - val_acc: 0.7849\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6233 - acc: 0.6183 - val_loss: 0.5075 - val_acc: 0.8180\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5877 - acc: 0.6497 - val_loss: 0.4864 - val_acc: 0.8491\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5648 - acc: 0.6764 - val_loss: 0.4619 - val_acc: 0.8668\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5435 - acc: 0.6962 - val_loss: 0.4460 - val_acc: 0.8743\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5244 - acc: 0.7142 - val_loss: 0.4302 - val_acc: 0.8855\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.5047 - acc: 0.7279 - val_loss: 0.4098 - val_acc: 0.8884\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.4878 - acc: 0.7405 - val_loss: 0.3890 - val_acc: 0.9033\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4707 - acc: 0.7523 - val_loss: 0.3639 - val_acc: 0.9141\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4550 - acc: 0.7648 - val_loss: 0.3496 - val_acc: 0.9129\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4400 - acc: 0.7750 - val_loss: 0.3360 - val_acc: 0.9136\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4229 - acc: 0.7877 - val_loss: 0.3071 - val_acc: 0.9328\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.4106 - acc: 0.7956 - val_loss: 0.3054 - val_acc: 0.9430\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 25us/step - loss: 1.7400 - acc: 0.5328 - val_loss: 0.8183 - val_acc: 0.5938\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 1.0022 - acc: 0.5540 - val_loss: 0.6972 - val_acc: 0.6369\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.8769 - acc: 0.5578 - val_loss: 0.6670 - val_acc: 0.6469\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.7874 - acc: 0.5769 - val_loss: 0.6236 - val_acc: 0.6496\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7381 - acc: 0.5882 - val_loss: 0.6145 - val_acc: 0.6689\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.7144 - acc: 0.5919 - val_loss: 0.6067 - val_acc: 0.6801\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6957 - acc: 0.6015 - val_loss: 0.6019 - val_acc: 0.6879\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6780 - acc: 0.6080 - val_loss: 0.5941 - val_acc: 0.6982\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6686 - acc: 0.6139 - val_loss: 0.5889 - val_acc: 0.7057\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6549 - acc: 0.6231 - val_loss: 0.5812 - val_acc: 0.7149\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6461 - acc: 0.6274 - val_loss: 0.5750 - val_acc: 0.7209\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6373 - acc: 0.6328 - val_loss: 0.5683 - val_acc: 0.7266\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6287 - acc: 0.6409 - val_loss: 0.5609 - val_acc: 0.7319\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 16us/step - loss: 0.6201 - acc: 0.6457 - val_loss: 0.5551 - val_acc: 0.7350\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 15us/step - loss: 0.6139 - acc: 0.6502 - val_loss: 0.5488 - val_acc: 0.7384\n",
      "Train on 106803 samples, validate on 45773 samples\n",
      "Epoch 1/15\n",
      "106803/106803 [==============================] - 3s 27us/step - loss: 1.5418 - acc: 0.5110 - val_loss: 0.8497 - val_acc: 0.5816\n",
      "Epoch 2/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 1.0108 - acc: 0.5346 - val_loss: 0.6963 - val_acc: 0.5931\n",
      "Epoch 3/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.8753 - acc: 0.5466 - val_loss: 0.6348 - val_acc: 0.6056\n",
      "Epoch 4/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7933 - acc: 0.5560 - val_loss: 0.6214 - val_acc: 0.6309\n",
      "Epoch 5/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7390 - acc: 0.5639 - val_loss: 0.6129 - val_acc: 0.6529\n",
      "Epoch 6/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.7114 - acc: 0.5738 - val_loss: 0.6038 - val_acc: 0.6738\n",
      "Epoch 7/15\n",
      "106803/106803 [==============================] - 2s 18us/step - loss: 0.6971 - acc: 0.5795 - val_loss: 0.5971 - val_acc: 0.6899\n",
      "Epoch 8/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6921 - acc: 0.5875 - val_loss: 0.5880 - val_acc: 0.7095\n",
      "Epoch 9/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6735 - acc: 0.5944 - val_loss: 0.5803 - val_acc: 0.7191\n",
      "Epoch 10/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6697 - acc: 0.5999 - val_loss: 0.5741 - val_acc: 0.7226\n",
      "Epoch 11/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6626 - acc: 0.6033 - val_loss: 0.5666 - val_acc: 0.7247\n",
      "Epoch 12/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6607 - acc: 0.6094 - val_loss: 0.5601 - val_acc: 0.7308\n",
      "Epoch 13/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6480 - acc: 0.6161 - val_loss: 0.5541 - val_acc: 0.7357\n",
      "Epoch 14/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6456 - acc: 0.6212 - val_loss: 0.5480 - val_acc: 0.7427\n",
      "Epoch 15/15\n",
      "106803/106803 [==============================] - 2s 17us/step - loss: 0.6406 - acc: 0.6263 - val_loss: 0.5428 - val_acc: 0.7488\n",
      "Current Loop\n",
      "8\n",
      "Time taken for this loop\n",
      "84.15483522415161\n",
      "Time left\n",
      "84.15483522415161\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001 \n",
    "training_epochs = 15\n",
    "batch_size = 1000\n",
    "\n",
    "opt = SGD(lr = learning_rate)\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 40 # 1st layer number of neurons\n",
    "n_hidden_2 = 20 # 2nd layer number of neurons\n",
    "n_hidden_3 = 10 # 2nd layer number of neurons\n",
    "\n",
    "n = 400 #number of loop\n",
    "\n",
    "for k in range(0,n):\n",
    "    t = time.time()\n",
    "    \n",
    "    #Random shuffle of dataset\n",
    "    numsample = len(wbp2)\n",
    "    idx = np.random.permutation(numsample) \n",
    "    wbp2 = [wbp2[i] for i in idx]\n",
    "    top1000 = [top1000[i] for i in idx]\n",
    "    bot1000 = [bot1000[i] for i in idx]\n",
    "    rand1000 = [rand1000[i] for i in idx]\n",
    "    \n",
    "    #Splitting of dataset into training and validation set\n",
    "    percent_train = 0.7\n",
    "    #Top1000\n",
    "    num_train = int(percent_train * numsample)\n",
    "    train_top_y = array(wbp2[0:num_train])\n",
    "    train_top_x = array(top1000[0:num_train])\n",
    "    test_top_y  = array(wbp2[num_train:numsample])\n",
    "    test_top_x  = array(top1000[num_train:numsample])\n",
    "    #Bot1000\n",
    "    train_bot_y = array(wbp2[0:num_train])\n",
    "    train_bot_x = array(bot1000[0:num_train])\n",
    "    test_bot_y  = array(wbp2[num_train:numsample])\n",
    "    test_bot_x  = array(bot1000[num_train:numsample])\n",
    "    #Rand1000\n",
    "    train_rand_y = array(wbp2[0:num_train])\n",
    "    train_rand_x = array(rand1000[0:num_train])\n",
    "    test_rand_y  = array(wbp2[num_train:numsample])\n",
    "    test_rand_x  = array(rand1000[num_train:numsample])\n",
    "\n",
    "    # convert class vectors to binary One Hot Encoded\n",
    "    n_classes = 2\n",
    "    train_top_y = keras.utils.to_categorical(train_top_y, n_classes)\n",
    "    test_top_y = keras.utils.to_categorical(test_top_y, n_classes)\n",
    "    train_bot_y = keras.utils.to_categorical(train_bot_y, n_classes)\n",
    "    test_bot_y = keras.utils.to_categorical(test_bot_y, n_classes)\n",
    "    train_rand_y = keras.utils.to_categorical(train_rand_y, n_classes)\n",
    "    test_rand_y = keras.utils.to_categorical(test_rand_y, n_classes)\n",
    "    \n",
    "    n_input_top =  len(train_top_x[0])\n",
    "    n_input_bot =  len(train_bot_x[0])\n",
    "    n_input_rand =  len(train_rand_x[0])\n",
    "    \n",
    "    Inp_top = Input(shape=(n_input_top,))\n",
    "    x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp_top)\n",
    "    x = Dropout(0.4, name = \"Dropout_01\")(x)\n",
    "    x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "    x = Dropout(0.4, name = \"Dropout_02\")(x)\n",
    "    x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "    output_top = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n",
    "    model_top = Model(Inp_top, output_top)\n",
    "    model_top.compile(loss='binary_crossentropy',\n",
    "              optimizer= opt,\n",
    "              metrics=['accuracy'])\n",
    "    history_top = model_top.fit(train_top_x, train_top_y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=training_epochs,\n",
    "                        verbose=1, # This is for what we want it to display out as it trains \n",
    "                        validation_data=(test_top_x, test_top_y))\n",
    "    \n",
    "    \n",
    "    Inp_bot = Input(shape=(n_input_bot,))\n",
    "    x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp_bot)\n",
    "    x = Dropout(0.4, name = \"Dropout_01\")(x)\n",
    "    x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "    x = Dropout(0.4, name = \"Dropout_02\")(x)\n",
    "    x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "    output_bot = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n",
    "    model_bot = Model(Inp_bot, output_bot)\n",
    "    model_bot.compile(loss='binary_crossentropy',\n",
    "              optimizer= opt,\n",
    "              metrics=['accuracy'])\n",
    "    history_bot = model_bot.fit(train_bot_x, train_bot_y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=training_epochs,\n",
    "                        verbose=1, # This is for what we want it to display out as it trains \n",
    "                        validation_data=(test_bot_x, test_bot_y))\n",
    "    \n",
    "    \n",
    "    Inp_rand = Input(shape=(n_input_rand,))\n",
    "    x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp_rand)\n",
    "    x = Dropout(0.4, name = \"Dropout_01\")(x)\n",
    "    x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "    x = Dropout(0.4, name = \"Dropout_02\")(x)\n",
    "    x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "    output_rand = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n",
    "    model_rand = Model(Inp_rand, output_rand)\n",
    "    model_rand.compile(loss='binary_crossentropy',\n",
    "              optimizer= opt,\n",
    "              metrics=['accuracy'])\n",
    "    history_rand = model_rand.fit(train_rand_x, train_rand_y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=training_epochs,\n",
    "                        verbose=1, # This is for what we want it to display out as it trains \n",
    "                        validation_data=(test_rand_x, test_rand_y))\n",
    "    \n",
    "    top_temp = history_top.history['val_acc']\n",
    "    top1000acc.append(top_temp)\n",
    "    bot_temp = history_bot.history['val_acc']\n",
    "    bot1000acc.append(bot_temp)\n",
    "    rand_temp = history_rand.history['val_acc']\n",
    "    rand1000acc.append(rand_temp)\n",
    "    if k%10 == 0:  #update csv every 10 loop\n",
    "        pd.DataFrame(top1000acc).to_csv(\"top1000_revised.csv\")\n",
    "        pd.DataFrame(bot1000acc).to_csv(\"bot1000_revised.csv\")\n",
    "        pd.DataFrame(rand1000acc).to_csv(\"rand1000_revised.csv\")\n",
    "    elapsed = time.time() - t\n",
    "    print('Current Loop')\n",
    "    print(k + 1)\n",
    "    print('Time taken for this loop')\n",
    "    print(elapsed)\n",
    "    print('Time left')\n",
    "    print(elapsed*(n-k-1))\n",
    "\n",
    "#Final save to file\n",
    "pd.DataFrame(top1000acc).to_csv(\"top1000_revised.csv\")\n",
    "pd.DataFrame(bot1000acc).to_csv(\"bot1000_revised.csv\")\n",
    "pd.DataFrame(rand1000acc).to_csv(\"rand1000_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top1000acc).to_csv(\"top1000_revised.csv\")\n",
    "pd.DataFrame(bot1000acc).to_csv(\"bot1000_revised.csv\")\n",
    "pd.DataFrame(rand1000acc).to_csv(\"rand1000_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
